# ğŸ† AI-Based Strategic Board Game

## ğŸ® Project Overview
This project implements an **AI-driven strategic board game**, developed as a term project for the **CSE462** course at Yeditepe University. The game is designed for a **7x7 board**, where an **AI (Player 1) competes against a human player (Player 2)**. The AI is built using **Min-Max, Q-Learning, or Deep Q-Learning Networks** to make strategic moves and defeat the opponent.

---

## ğŸ“œ Game Rules & Mechanics

### ğŸ Initial Setup
- The game board consists of **7 rows Ã— 7 columns**.
- **Triangle (â–³) pieces** represent the AI (**Player 1**).
- **Circle (â—‹) pieces** represent the human player (**Player 2**).
- Each player starts with **4 pieces** placed in a specific formation.
- The **AI always makes the first move**.

### ğŸ² Move Rules
âœ” Pieces **can move horizontally and vertically**.
âœ” **No diagonal moves** allowed.
âœ” If a player has **multiple pieces**, they must make **two consecutive moves**.
âœ” If a player has **only one piece**, they can **only make one move**.

### ğŸ”¥ Capturing System
- A piece (or group of pieces) is **captured** if:
  - It is **trapped between an opponentâ€™s piece and the board edge**.
  - It is **sandwiched between two opponent pieces**.
  - Both players' pieces are trapped between opponent pieces, leading to **multiple captures**.

### ğŸ† Win Conditions
- **Draw**:
  - Both players have **no pieces left**.
  - Both players have **only one piece left**.
- **Victory**:
  - The opponent has **no remaining pieces**.
  - After **50 total moves**, the player with **more pieces wins**.
- **Defeat**:
  - The player has **no pieces left**, but the opponent does.
  - After **50 moves**, the player with **fewer pieces loses**.

---

## ğŸ¤– AI Implementation
The AI engine is built using **advanced decision-making algorithms** to maximize efficiency and strategic play.

### **1ï¸âƒ£ Min-Max Algorithm**
ğŸ”¹ Evaluates possible future moves and assigns scores.
ğŸ”¹ Selects the move that **maximizes advantage** while minimizing the opponent's.
ğŸ”¹ Can be optimized using **Alpha-Beta pruning**.

### **2ï¸âƒ£ Q-Learning (Reinforcement Learning)**
ğŸ”¹ AI **learns from experience**, improving over time.
ğŸ”¹ Rewards **optimal moves**, penalizes **bad decisions**.
ğŸ”¹ Makes AI more adaptable.

### **3ï¸âƒ£ Deep Q-Learning Networks (DQN)**
ğŸ”¹ Uses **Neural Networks** to predict the best moves.
ğŸ”¹ Allows for **dynamic, self-learning AI**.
ğŸ”¹ More computationally intensive but highly effective.

---

## ğŸ› ï¸ Technical Implementation

### **ğŸ¨ User Interface**
âœ” **Supports CLI & GUI** versions.
âœ” Allows players to **input moves, view board state, and track AI decisions**.

### **ğŸ“Œ Move Validation & Capture Detection**
âœ” Ensures only **valid moves** are executed.
âœ” **Automatically detects and removes captured pieces**.
âœ” Implements **turn-based gameplay rules**.

### **ğŸ“Š Turn Management & Move Counter**
âœ” Tracks total moves and **enforces the 50-move rule**.
âœ” Ensures **AI moves first**.
âœ” Prevents illegal moves.
